%!TEX root = main.tex

\subsection{Big Stream Processing Systems} 
\label{sec:tut_systems}
%\begin{alltt}TODO\scriptsize 0.75/1 pages
%\end{alltt}

In this tutorial we first identified the most differentiating characteristic of scalable data stream processing systems that is the notion of data as a continuous, possibly infinite resource instead of ``facts and statistics organised and collected together for future reference or analysis''~\footnote{Definition of ``data'' according to Google Dictionary}. In fact, data stream processing systems broaden their context from retrospective data analysis to continuous, unbounded processing coupled with scalable and persistent application state.  Various forms of stream processing have been employed in the past within respective domains, such as network-centric processing on byte streams, functional (e.g., monads) and actor programming, complex event processing and database materialized views. Besides, \emph{stream management} has been an active research field for decades \cite{cherniack2003scalable,chandrasekaran2003telegraphcq,abadi2003aurora,arasu2004stream}. Nonetheless, several of these ideas have been only just recently put consistently together to compose a stack (see Figure \ref{fig:streamstack}) centered around the notion of data as an unbounded partitioned stream of records. Most importantly, stream processing did not restrict but complemented existing scalable processing models (e.g., MapReduce \cite{dean2008mapreduce}) with persistent partitioned state, time domains and flexible scoping using stream windows. The three levels of the general scalable data streaming stack address storage, compute and query support.

\begin{figure}[t]
\centering
\includegraphics[width=0.4 \textwidth]{pictures/streamstack.pdf}
\caption{The Stack of Scalable Stream Processing}
\label{fig:streamstack}
\end{figure}

\para{Stream Storage: }Data dissemination from consumers to producers is a problem that has been revisited multiple times with different assumptions and needs in mind. In the context of data streaming, direct communication (e.g., TCP channels) was not an option despite low-latency requirements, since it required application ingestion to be actively in-sync with data creation while also lacking the transparency and durability properties that are the norm in today's cloud computing ecosystem. Furthermore, message brokers (e.g., RabbitMQ, JMS) were insufficient for the needs of supporting multiple applications and configurations (i.e., task parallelism). Thus, a class of open-source stream storage systems based on \emph{partitioned replicated logs} was introduced, led by Apache Kafka \cite{kreps2011kafka} and more recently Pravega \cite{CUSTOM:web/pravega} as well as proprietary cloud services such as Amazon Kinesis. Partitioned replicated logs provide high sequential read and write throughput by exploiting copy-on-write and strict data-parallel access by distinct consumers. Furthermore, they bookkeep data access (offset-based) for the purposes of data reprocessing, reconfiguration and roll-backs among others. Finally, effort has been put to support transactional logging and repartitioning allowing for seamless integration with modern stream compute systems.

\para{Stream Compute: } We further divide compute into \emph{programming models} and \emph{runtime engines}. In terms of programming model support, there has been a shift from purely event-based, compositional models (e.g., \emph{Apache Storm} \cite{CUSTOM:web/Storm}) to more declarative representations ~\cite{carbone_et_al_2015,akidau2015dataflow,CUSTOM:web/apex,zaharia_et_al_2013,CUSTOM:web/kafkastreams}. Currently, most standard APIs are fluid, functional and allow declaring relational transformations (e.g., joins, filters etc.) while providing first-class support for persistent partitioned state, stream windows and event-time progress using watermarks. The latter allowed application logic to incorporate timers that operate consistently on different time domains (e.g., origin-time), thus allowing out of order processing~\cite{li2008out},  a concept popularized by Google \cite{millwheel,akidau2015dataflow}. 

With respect to runtime engines, we observe certain converging commonalities such as a dataflow execution model, explicit locally embedded state and asynchronous state snapshotting for fault tolerance and reconfiguration support \cite{state2017carbone,jacques2016consistent}. Apache Spark \cite{zaharia_et_al_2013}, as a special case, emulates data streaming by slicing computation into recurring batch jobs, yet, it currently makes use of locally embedded state and is planned to adopt a continuous processing runtime as well for the purposes of low-latency data streaming \cite{CUSTOM:web/sparkcontinuous}.

\para{Domain-Specific Libraries: }A concluding discussion in this tutorial addressed the prospects of standardizing domain-specific libraries such as Stream SQL, CEP, Online Machine Learning and User-Defined Windows \cite{carbone2015cutty} as well as system runtime concepts that are indirectly exposed to the user such as state snapshots \cite{state2017carbone}. Several of these initiatives can already be observed in the effort of Apache Beam \cite{CUSTOM:web/beam} and Calcite \cite{CUSTOM:web/calcite} to serve as standard cross-runtime frameworks supported by different runtimes \cite{CUSTOM:web/beamcapabilitymatrix}.
